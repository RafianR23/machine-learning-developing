# -*- coding: utf-8 -*-
"""MLSubmission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L2PyCApUeuF5UHu2P81Ta-c6CV4vw0P-

#Biodata

*   Nama : Rafian Ramadhani
*   Username : Rafian
*   Email : rafianramadhani@gmail.com
*   Pekerjaan : Mahasiswa
*   Link Googlecollab :
https://colab.research.google.com/drive/1L2PyCApUeuF5UHu2P81Ta-c6CV4vw0P-?usp=sharing

#Install Tensorflow dan Panggil Library yang dibutuhkan
"""

import tensorflow as tf
print(tf.__version__)

from tensorflow import keras
from keras import layers
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""#Download Data"""

!wget --no-check-certificate \
  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip

"""#Inisiasi Lokasi Data"""

# melakukan ekstraksi pada file zip
import zipfile,os
local_zip = 'rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/latianml')
zip_ref.close()

base_dir = '/latianml/rockpaperscissors'

import shutil
shutil.rmtree(os.path.join(base_dir, 'rps-cv-images'))
os.remove(os.path.join(base_dir, 'README_rpc-cv-images.txt'))

os.listdir(base_dir)

"""#Lakukan Image Generator untuk Persiapan dan Split Data"""

train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=90,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest',
                    validation_split = 0.2)

train_generator = train_datagen.flow_from_directory(
        base_dir,  # direktori data latih
        target_size=(150, 150),
        batch_size=32,
        class_mode='categorical',
        shuffle = True,
        subset='training')

val_generator = train_datagen.flow_from_directory(
        base_dir, # direktori data validasi
        target_size=(150, 150),
        batch_size=32, 
        class_mode='categorical',
        shuffle = True,
        subset='validation')

"""#Arsitektur CNN"""

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

"""#Compile model dengan 'adam' optimizer loss function Category Crossentropy """

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.92 and logs.get('val_accuracy')>0.92):
      print("\nAccuracy above 92%, finish training!")
      self.model.stop_training = True

callbacks = myCallback()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

"""#Train Model"""

history = model.fit(
             train_generator,
             steps_per_epoch=25,  
             epochs=20,
             validation_data=val_generator, 
             validation_steps=5, 
             callbacks = [callbacks], 
             verbose=2)

"""#EDA Hasil Prediksi"""

import matplotlib.pyplot as plt
import seaborn as sns

akurasi = hasil.history['accuracy']
vallidasi_akurasi = hasil.history['val_accuracy']

loss = hasil.history['loss']
validasi_loss = hasil.history['val_loss']

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

# Konversi model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

# The '.h5' extension indicates that the model should be saved to HDF5.
model.save('my_model.pb')

